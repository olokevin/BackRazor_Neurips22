project: 'default'

path: null
eval_only: false
debug: false
# gpu: '0'
resume: 0
manual_seed: 0

### RunConfig: dataset related ###
dataset: flowers102
# choices=[
#     'aircraft', 'car', 'flowers102',
#     'food101', 'cub200', 'pets',
#     'cifar10', 'cifar100', 'ImageNet',])
init_new_head: true

train_batch_size: 8
test_batch_size: 100
valid_size: null  # use test set as validation set

n_worker: 8
# n_worker: 10
resize_scale: 0.22
distort_color: 'torch'
# choices=['tf', 'torch', 'None'])
image_size: 224

### RunConfig: optimization related ###
n_epochs: 50
init_lr: 0.05
lr_schedule_type: 'cosine'

opt_type: 'adam'
# choices=['sgd', 'adam'])
momentum: 0.9
no_nesterov: false
weight_decay: 0
no_decay_keys: 'bn#bias'
# choices=['None', 'bn', 'bn#bias', 'bias'])
label_smoothing: 0.7

validation_frequency: 1
grad_accumulation_steps: 1

### net config ###
net: 'proxyless_mobile'
# choices=['proxyless_mobile', 'resnet', 'mcunet'])
dropout: 0.2
ws_eps: 0.00001
net_path: null
fix_bn_stat: false

pretrained: true
pretrain_model_path: null

### transfer learning configs ###
transfer_learning_method: 'tinytl-lite_residual+bias'
# choices=[
#   'full', 'full_noBN', 'bn+last', 'last',
#   'tinytl-bias', 'tinytl-lite_residual', 'tinytl-lite_residual+bias'])

train_first_conv: false
trainable_blocks: null
trainable_layers: null
grad_output_prune_ratio: null

origin_network: false

replace_norm_layer: null
gn_channel_per_group: null

backRazor: false
backRazor_pruneRatio: 0.8
backRazor_pruneRatio_head: -1
backRazor_act_prune: false

### lite residual module configs ###
lite_residual_downsample: 2
lite_residual_expand: 1
lite_residual_groups: 2
lite_residual_ks: 5
random_init_lite_residual: false

### weight quantization ###
weight_quantization: true
frozen_param_bits: 8

### weight standardization ###
weight_standardization: true

ZO_Estim:
  en: false